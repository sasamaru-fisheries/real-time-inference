"""Utilities for training, evaluating, and exporting a Titanic RandomForest pipeline.

このファイルは以下の責務を持っています。

1. コマンドライン引数の解釈（`argparse`）。
2. データ読み込み・前処理パイプラインの構築。
3. Optuna を用いた簡易ハイパーパラメータ探索。
4. 学習済みモデルの pickle 保存とレポート（分類レポート、ROC 曲線）の出力。

初心者向けに、なぜこの処理が必要なのかをコード内に丁寧にコメントしています。
"""

import argparse
import json
from pathlib import Path

import joblib
import optuna
import pandas as pd
from sklearn.compose import ColumnTransformer
from sklearn.ensemble import RandomForestClassifier
from sklearn.impute import SimpleImputer
from sklearn.metrics import (
    accuracy_score,
    classification_report,
    roc_auc_score,
    roc_curve,
)
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler

import matplotlib

# 画像をファイルに保存するだけなので、X サーバの無い環境でも動くようにバックエンドを固定
matplotlib.use("Agg")
import matplotlib.pyplot as plt


# ルートパスを計算しておくと、プロジェクト内のどこから実行しても同じ相対パスを参照できる
BASE_DIR = Path(__file__).resolve().parent
ROOT_DIR = BASE_DIR.parent
# データ、モデル、レポートのデフォルト出力先。
# CLI から `--data` 等で上書き可能にして柔軟性を確保するのがベストプラクティス。
DEFAULT_DATA = ROOT_DIR / "data" / "Titanic-Dataset.csv"
DEFAULT_TEST_DATA = ROOT_DIR / "data" / "Titanic-Dataset.csv"
DEFAULT_MODEL_PATH = ROOT_DIR / "models" / "titanic" / "random_forest_pipeline.pkl"
DEFAULT_REPORT_DIR = ROOT_DIR / "reports" / "titanic" / "random_forest"


FEATURES = ["Pclass", "Sex", "Age", "SibSp", "Parch", "Fare", "Embarked"]
TARGET = "Survived"


def build_pipeline(random_state: int, params: dict) -> Pipeline:
    """学習で使う前処理 + 推論器のパイプラインを構築する。

    random_state
        再現性確保のため RandomForest に設定する乱数シード。
    params
        Optuna で探索したハイパーパラメータを辞書で受け取る。

    scikit-learn の Pipeline / ColumnTransformer を使うことで、
    PD.DataFrame の列名を保ったまま、数値とカテゴリ列の処理をまとめて表現できる。
    """
    numeric_features = ["Age", "SibSp", "Parch", "Fare"]
    categorical_features = ["Pclass", "Sex", "Embarked"]

    # 数値列の欠損には中央値で埋め、スケールを合わせる。
    # StandardScaler を使うことで学習が安定しやすくなる。
    numeric_transformer = Pipeline(
        steps=[
            ("imputer", SimpleImputer(strategy="median")),
            ("scaler", StandardScaler()),
        ]
    )
    categorical_transformer = Pipeline(
        steps=[
            ("imputer", SimpleImputer(strategy="most_frequent")),
            ("encoder", OneHotEncoder(handle_unknown="ignore")),
        ]
    )

    # ColumnTransformer で列ごとの処理を分岐させる。
    # こうしておけば PMML / ONNX へエクスポートするときも前処理を丸ごと含められる。
    preprocessor = ColumnTransformer(
        transformers=[
            ("num", numeric_transformer, numeric_features),
            ("cat", categorical_transformer, categorical_features),
        ]
    )

    model = RandomForestClassifier(
        n_estimators=params["n_estimators"],
        max_depth=params["max_depth"],
        min_samples_split=params["min_samples_split"],
        min_samples_leaf=params["min_samples_leaf"],
        max_features=params["max_features"],
        bootstrap=params["bootstrap"],
        n_jobs=-1,
        random_state=random_state,
    )

    return Pipeline(steps=[("preprocess", preprocessor), ("model", model)])


def load_dataset(path: Path) -> tuple[pd.DataFrame, pd.Series]:
    """CSV ファイルから特徴量とターゲットを読み込む。

    - 欠損があると RandomForest では学習できないため、まず `TARGET` 列の欠損を落とす。
    - 以降の処理で列名が失われないよう、`copy()` で明示的に複製してから返す。
    """
    df = pd.read_csv(path)
    missing_cols = set(FEATURES + [TARGET]) - set(df.columns)
    if missing_cols:
        raise ValueError(f"Dataset {path} is missing required columns: {missing_cols}")

    df = df.dropna(subset=[TARGET])
    X = df[FEATURES].copy()
    y = df[TARGET].astype(int)
    return X, y


def sanitize_label(label: str) -> str:
    return label.lower().replace(" ", "_")


def evaluate(
    model: Pipeline,
    X_test: pd.DataFrame,
    y_test: pd.Series,
    label: str,
    output_dir: Path,
) -> None:
    """検証用データでモデルを評価し、レポートや ROC 曲線を出力する。"""
    preds = model.predict(X_test)
    proba = model.predict_proba(X_test)[:, 1]
    report = classification_report(y_test, preds)
    roc_auc = roc_auc_score(y_test, proba)
    acc = accuracy_score(y_test, preds)
    fpr, tpr, _ = roc_curve(y_test, proba)

    print(f"\n=== Evaluation on {label} set ===")
    print(report)
    print(f"ROC AUC: {roc_auc:.4f}")

    output_dir.mkdir(parents=True, exist_ok=True)
    label_key = sanitize_label(label)

    report_path = output_dir / f"{label_key}_classification_report.txt"
    with report_path.open("w") as f:
        f.write(report)

    metrics = {
        "roc_auc": roc_auc,
        "accuracy": acc,
        "support": len(y_test),
    }
    metrics_path = output_dir / f"{label_key}_metrics.json"
    with metrics_path.open("w") as f:
        json.dump(metrics, f, indent=2)

    plt.figure(figsize=(6, 6))
    plt.plot(fpr, tpr, label=f"ROC curve (AUC = {roc_auc:.4f})")
    plt.plot([0, 1], [0, 1], "k--", label="Random")
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title(f"ROC Curve - {label}")
    plt.legend(loc="lower right")
    roc_path = output_dir / f"{label_key}_roc_curve.png"
    plt.tight_layout()
    plt.savefig(roc_path, dpi=120)
    plt.close()


def parse_args() -> argparse.Namespace:
    """CLI 引数の定義とパース。

    なるべく値をハードコードせず、CLI から上書きできるようにしておくと
    スクリプトが再利用しやすくなる。
    """
    parser = argparse.ArgumentParser(description="Train RandomForest on Titanic dataset.")
    parser.add_argument(
        "--data",
        type=Path,
        default=DEFAULT_DATA,
        help="Path to the Titanic CSV file.",
    )
    parser.add_argument(
        "--model-path",
        type=Path,
        default=DEFAULT_MODEL_PATH,
        help="Where to store the trained model pipeline.",
    )
    parser.add_argument(
        "--test-data",
        type=Path,
        default=DEFAULT_TEST_DATA,
        help="External dataset used only for final evaluation.",
    )
    parser.add_argument(
        "--test-size",
        type=float,
        default=0.2,
        help="Fraction of data for validation/test split.",
    )
    parser.add_argument(
        "--random-state",
        type=int,
        default=42,
        help="Random seed for reproducibility.",
    )
    parser.add_argument(
        "--n-trials",
        type=int,
        default=1,
        help="Number of Optuna trials for hyperparameter search.",
    )
    parser.add_argument(
        "--tune-sample-size",
        type=int,
        default=200_000,
        help="Number of rows to use during hyperparameter tuning (use entire dataset if smaller or if set to 0).",
    )
    parser.add_argument(
        "--report-dir",
        type=Path,
        default=DEFAULT_REPORT_DIR,
        help="Directory to store evaluation reports and plots.",
    )
    return parser.parse_args()


def tune_hyperparameters(
    X: pd.DataFrame,
    y: pd.Series,
    test_size: float,
    random_state: int,
    n_trials: int,
    sample_size: int,
) -> dict:
    """Optuna を使ってハイパーパラメータを探索する。

    - データセットが大きい場合は `sample_size` でサブセットにして高速化。
    - 返り値は `build_pipeline` にそのまま渡せる辞書。
    """
    if sample_size > 0 and len(X) > sample_size:
        X, _, y, _ = train_test_split(
            X,
            y,
            train_size=sample_size,
            stratify=y,
            random_state=random_state,
        )

    def objective(trial: optuna.trial.Trial) -> float:
        params = {
            "n_estimators": trial.suggest_int("n_estimators", 200, 800),
            "max_depth": trial.suggest_int("max_depth", 4, 20),
            "min_samples_split": trial.suggest_int("min_samples_split", 2, 8),
            "min_samples_leaf": trial.suggest_int("min_samples_leaf", 1, 6),
            "max_features": trial.suggest_categorical(
                "max_features", ["sqrt", "log2", None]
            ),
            "bootstrap": trial.suggest_categorical("bootstrap", [True, False]),
        }

        pipeline = build_pipeline(random_state, params)
        X_train, X_valid, y_train, y_valid = train_test_split(
            X,
            y,
            test_size=test_size,
            random_state=random_state,
            stratify=y,
        )
        pipeline.fit(X_train, y_train)
        proba = pipeline.predict_proba(X_valid)[:, 1]
        return roc_auc_score(y_valid, proba)

    study = optuna.create_study(
        direction="maximize",
        sampler=optuna.samplers.TPESampler(seed=random_state),
    )
    study.optimize(objective, n_trials=n_trials, show_progress_bar=False)
    print(f"Best trial ROC AUC: {study.best_value:.4f}")
    print(f"Best params: {study.best_params}")
    return study.best_params


def main() -> None:
    """エントリーポイント。

    - 引数読み込み
    - データロード
    - ハイパーパラメータ探索
    - モデル学習
    - 評価（ROC 曲線やテキストレポートの保存）
    - pickle 保存
    の順番で処理する。
    """
    args = parse_args()
    X_train_full, y_train_full = load_dataset(args.data)
    X_external, y_external = load_dataset(args.test_data)

    best_params = tune_hyperparameters(
        X_train_full,
        y_train_full,
        args.test_size,
        args.random_state,
        args.n_trials,
        args.tune_sample_size,
    )

    pipeline = build_pipeline(args.random_state, best_params)
    pipeline.fit(X_train_full, y_train_full)
    evaluate(
        pipeline,
        X_external,
        y_external,
        label="external test",
        output_dir=args.report_dir,
    )

    args.model_path.parent.mkdir(parents=True, exist_ok=True)
    joblib.dump(pipeline, args.model_path)
    print(f"Saved RandomForest pipeline to {args.model_path}")


if __name__ == "__main__":
    main()
